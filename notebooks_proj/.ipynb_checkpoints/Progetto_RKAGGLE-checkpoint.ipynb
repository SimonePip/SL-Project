{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_veeJ32BrfR"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zxRpUUr-BnaJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9Lk7tXbB_Vf"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4TPaksx6CCw2"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset_completo', header ='infer').iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titles elaboration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/simone/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import *\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(string):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    string=tokenizer.tokenize(string)\n",
    "    for word in range(len(string)):\n",
    "        string[word] = string[word].lower() \n",
    "    #Remove stopwords\n",
    "    string = [word for word in string if not word in stopwords.words()]\n",
    "    #STEMMING\n",
    "    stemmer = PorterStemmer()\n",
    "    string = [stemmer.stem(word) for word in string]\n",
    "    return \" \".join(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4433it [01:24, 52.34it/s]\n"
     ]
    }
   ],
   "source": [
    "#remove all the bad stuff we don't need\n",
    "titles=list(data['titolo'])\n",
    "for i,title in tqdm(enumerate(titles)):\n",
    "    titles[i]=clean(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total number of different words is:  13015\n",
      "the total number of words is:  25322\n"
     ]
    }
   ],
   "source": [
    "#create dictionary with key the word and value the number of times it has been seen\n",
    "diz={}\n",
    "for title in titles:\n",
    "    for word in title.split(' '):\n",
    "        if word in diz:\n",
    "            diz[word]+=1\n",
    "        else:\n",
    "            diz[word]=1  \n",
    "print('the total number of different words is: ',len(diz.keys()))\n",
    "print('the total number of words is: ',np.sum(list(diz.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update value of the dictionary with its prob computed as #(times is observed)/#(total words)\n",
    "tot=np.sum(list(diz.values()))\n",
    "for key in diz.keys():\n",
    "    diz[key]=diz[key]/tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 4433/4433 [00:00<00:00, 537442.18it/s]\n"
     ]
    }
   ],
   "source": [
    "prob_title=[]\n",
    "for title in tqdm(titles):\n",
    "    somma=0\n",
    "    for word in title.split(' '):\n",
    "        somma+=(diz[word])\n",
    "    prob_title.append(somma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(columns = ['titolo'])\n",
    "data['titolo']=prob_title\n",
    "data['titolo']=(data['titolo']-data['titolo'].min())/(data['titolo'].max()-data['titolo'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1SjeiTzLDz3J"
   },
   "source": [
    "# Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nk6Vu9B8FKUC"
   },
   "source": [
    "### Train Test Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zPpV61yRFRd2"
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KAXqkuGSRo6C",
    "outputId": "a43f65dd-42dd-4825-810a-8a25c90118cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['durata', 'views', 'n_comments', 'n_like', 'genere', 'publ',\n",
       "       'max_quality', 'score', 'timedelta', 'class', 'titolo'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Vh8Mxd3IFn3-"
   },
   "outputs": [],
   "source": [
    "Y = data['class'] # Extract the target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "TjwRGC1LF_yM"
   },
   "outputs": [],
   "source": [
    "X = data.drop(columns = ['class','score','publ']) # Remove from the data useful to the analysis: \"score, publ, titolo, class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "4kcZ6zbkM71k"
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "X['genere'] = le.fit_transform(X['genere']) # Transform the Categorical genere feature in a numerical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "5xfQwZB6GN5C"
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,Y, train_size=.8, random_state=42) # Split dataset in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "NnylF4nyHP05"
   },
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val = train_test_split(X_train,y_train, train_size = .8, random_state = 42) # Split train in train and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "McL-rf4EIETM"
   },
   "source": [
    "### Excursus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfJ_pNuoIggO"
   },
   "source": [
    "We want to predict the class of a given video. The classes were defined using a home-made score.\n",
    "\n",
    "To predict we will try different models.\n",
    "Let's start with SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sihcOc9uI77Y",
    "tags": []
   },
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Nf67Y6igJRo7"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxSP1WkcJzIn"
   },
   "source": [
    "REMINDER OF THE PARAMETERS\n",
    "\n",
    "\n",
    "C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=- 1, decision_function_shape='ovr', break_ties=False, random_state=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOwe20T2JYWN"
   },
   "source": [
    "Try to use SVC without scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sT1V1xqOMskK",
    "outputId": "d81d3c1e-2765-47f5-ea02-3ba82ae68a3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16061185468451242\n",
      "0.4732394366197183 0.25\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(gamma = 'auto', random_state = 42)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "print(f1_score(y_val, y_pred, average = 'macro'))\n",
    "print(accuracy_score(y_val, y_pred), recall_score(y_val, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vbBrjFoJUAIv"
   },
   "source": [
    "Try to use SVC with Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GOLK38YuUIO0",
    "outputId": "5e42c141-5d75-487d-cf12-62154784483d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8001545157307074\n",
      "0.8183098591549296 0.7949318076745261\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto',random_state = 42))\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "print(f1_score(y_val, y_pred, average = 'macro'))\n",
    "print(accuracy_score(y_val, y_pred), recall_score(y_val, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKoLo8RcUuK8"
   },
   "source": [
    "Try to use SVC with MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6R5IQpLSU1f0",
    "outputId": "618acf6f-65ca-457b-a5fe-f0450fc43bbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5908952871236659\n",
      "0.7394366197183099 0.5721278317152104\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(MinMaxScaler(), SVC(gamma='auto',random_state = 42))\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "print(f1_score(y_val, y_pred, average = 'macro'))\n",
    "print(accuracy_score(y_val, y_pred), recall_score(y_val, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r4nb9eD-VBc_"
   },
   "source": [
    "Try to use SVC with MinMaxScaler and Standard Scaler (in that order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h-zC-ZjtVKW0",
    "outputId": "fb50c2aa-3bc6-4266-b11c-d5bc2b1c4250"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8001545157307074\n",
      "0.8183098591549296 0.7949318076745261\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(MinMaxScaler(),StandardScaler(), SVC(gamma='auto',random_state = 42))\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "print(f1_score(y_val, y_pred, average = 'macro'))\n",
    "print(accuracy_score(y_val, y_pred), recall_score(y_val, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSCZ8ep5VZmm"
   },
   "source": [
    "Try to use SVC with Standard Scaler and MinMaxScaler (in that order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GXpKohSrVhH_",
    "outputId": "b1cc0eb0-10ed-4ebd-e7be-08217907a407"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5908952871236659\n",
      "0.7394366197183099 0.5721278317152104\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(StandardScaler(),MinMaxScaler(), SVC(gamma='auto',random_state = 42))\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "print(f1_score(y_val, y_pred, average = 'macro'))\n",
    "print(accuracy_score(y_val, y_pred), recall_score(y_val, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JzDW9SRVpeJ"
   },
   "source": [
    "Same Results as One Scaler.\n",
    "\n",
    "\n",
    "Best Results without Scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QUL7jdepWgXj",
    "outputId": "8b1e9ee6-3af7-487f-f941-0437878d52a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "\n",
    "#def gridsearch\n",
    "params = {\n",
    "    'kernel' : ('poly', 'rbf', 'sigmoid'),\n",
    "    'C' : np.linspace(1, 100, num=5), \n",
    "    #'degree' : [3,5,8],\n",
    "    #'gamma' : ('auto','scale')\n",
    "    \n",
    "}\n",
    "\n",
    "search = GridSearchCV(svc,param_grid=params,scoring='f1_macro',\n",
    "                                  n_jobs=-1, refit=True, verbose=10, pre_dispatch='10*n_jobs',\n",
    "                                  return_train_score=True)\n",
    "search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5rYVhLC7aiLn"
   },
   "outputs": [],
   "source": [
    "best_one=search.best_estimator_\n",
    "y_pred = best_one.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UUMPjA_rawaJ"
   },
   "outputs": [],
   "source": [
    "f1_score(y_val, y_pred, average = 'macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PGUfbcicdG2b",
    "tags": []
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w9jsJjJCczXZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OwUC3P8tc41w"
   },
   "outputs": [],
   "source": [
    "clf = RFC(random_state = 42)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "print('f1-score using Random Forest without scaling data: ',f1_score(y_val, y_pred, average = 'macro'))\n",
    "print(accuracy_score(y_val, y_pred), recall_score(y_val, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mKM5dKSUc9lt"
   },
   "outputs": [],
   "source": [
    "clf = make_pipeline(MinMaxScaler(), RFC(random_state = 42))\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "print(f1_score(y_val, y_pred, average = 'macro'))\n",
    "print(accuracy_score(y_val, y_pred), recall_score(y_val, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mkR3VGIcdATZ"
   },
   "outputs": [],
   "source": [
    "clf = make_pipeline(StandardScaler(), RFC(random_state = 42))\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "print(f1_score(y_val, y_pred, average = 'macro'))\n",
    "print(accuracy_score(y_val, y_pred), recall_score(y_val, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SSoHJ33mdEgY"
   },
   "outputs": [],
   "source": [
    "clf = make_pipeline(MinMaxScaler(), RFC(random_state = 42, n_jobs = -1))\n",
    "\n",
    "#def gridsearch\n",
    "params = {'randomforestclassifier__criterion' : ['gini','entropy'],\n",
    "          'randomforestclassifier__max_features' : [None],\n",
    "          'randomforestclassifier__n_estimators' : [50,100,200]\n",
    "         }\n",
    "\n",
    "search = GridSearchCV(clf,param_grid=params,scoring='f1_macro',\n",
    "                                  n_jobs=-1,refit=True,verbose=10, pre_dispatch='10*n_jobs',\n",
    "                                  return_train_score=True)\n",
    "search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Xb7hb4jdUF8"
   },
   "outputs": [],
   "source": [
    "best_one=search.best_estimator_\n",
    "y_pred = best_one.predict(X_val)\n",
    "print(accuracy_score(y_val, y_pred), recall_score(y_val, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ghV7IJqudY3X"
   },
   "outputs": [],
   "source": [
    "f1_score(y_val, y_pred, average = 'macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PGUfbcicdG2b",
    "tags": []
   },
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w9jsJjJCczXZ"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OwUC3P8tc41w"
   },
   "outputs": [],
   "source": [
    "clf = XGBClassifier(random_state=42)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "print('f1-score using XGBoost without scaling data: ',f1_score(y_val, y_pred, average = 'macro'))\n",
    "print(accuracy_score(y_val, y_pred), recall_score(y_val, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mKM5dKSUc9lt"
   },
   "outputs": [],
   "source": [
    "clf = make_pipeline(MinMaxScaler(), XGBClassifier(random_state=42))\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "print('f1-score using XGBoost using MinMaxScaler: ',f1_score(y_val, y_pred, average = 'macro'))\n",
    "print(accuracy_score(y_val, y_pred), recall_score(y_val, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mkR3VGIcdATZ"
   },
   "outputs": [],
   "source": [
    "clf = make_pipeline(StandardScaler(), XGBClassifier(random_state=42))\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "print('f1-score using XGBoost using StandardScaler: ',f1_score(y_val, y_pred, average = 'macro'))\n",
    "print(accuracy_score(y_val, y_pred), recall_score(y_val, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SSoHJ33mdEgY"
   },
   "outputs": [],
   "source": [
    "clf = make_pipeline(MinMaxScaler(), XGBClassifier(random_state=42))\n",
    "\n",
    "#def gridsearch\n",
    "params = {'xgbclassifier__learning_rate' : [.2,.3,.4],\n",
    "          'xgbclassifier__n_estimators' : [600,800,1000]\n",
    "         }\n",
    "\n",
    "search = GridSearchCV(clf,param_grid=params,scoring='f1_macro',\n",
    "                                  n_jobs=-1,refit=True,verbose=10, pre_dispatch='10*n_jobs',\n",
    "                                  return_train_score=True)\n",
    "search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params=search.best_params_\n",
    "xgb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Xb7hb4jdUF8"
   },
   "outputs": [],
   "source": [
    "best_one=search.best_estimator_\n",
    "y_pred = best_one.predict(X_val)\n",
    "print(accuracy_score(y_val, y_pred), recall_score(y_val, y_pred, average='macro'), f1_score(y_val, y_pred, average = 'macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### One vs Rest Classifier - ORCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier as ORC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=make_pipeline(MinMaxScaler(), XGBClassifier(learning_rate=xgb_params['xgbclassifier__learning_rate'],n_estimators=xgb_params['xgbclassifier__n_estimators'],random_state=42))\n",
    "classifier=ORC(clf)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_val)\n",
    "print(accuracy_score(y_val, y_pred), recall_score(y_val, y_pred, average='macro'), f1_score(y_val, y_pred, average = 'macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### One vs One Classifier - ORCO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier as OOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=make_pipeline(MinMaxScaler(), XGBClassifier(learning_rate=xgb_params['xgbclassifier__learning_rate'],n_estimators=xgb_params['xgbclassifier__n_estimators'],random_state=42))\n",
    "classifier=OOC(clf)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_val)\n",
    "print(accuracy_score(y_val, y_pred), recall_score(y_val, y_pred, average='macro'), f1_score(y_val, y_pred, average = 'macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(StandardScaler(), LogisticRegression(random_state=42, multi_class = 'multinomial',\n",
    "                                                         solver = 'newton-cg',\n",
    "                                                         n_jobs = -1))\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "print('F1 SCORE: ',f1_score(y_val, y_pred, average = 'macro'))\n",
    "print('PRECISION:',precision_recall_fscore_support(y_val, y_pred, average='macro')[0])\n",
    "print('RECALL:',precision_recall_fscore_support(y_val, y_pred, average='macro')[1])\n",
    "print('ACCURACY:', sum(y_pred == y_val)/len(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(StandardScaler(),KNeighborsClassifier(n_jobs = -1) )\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "print('F1 SCORE: ',f1_score(y_val, y_pred, average = 'macro'))\n",
    "print('PRECISION:',precision_recall_fscore_support(y_val, y_pred, average='macro')[0])\n",
    "print('RECALL:',precision_recall_fscore_support(y_val, y_pred, average='macro')[1])\n",
    "print('ACCURACY:', sum(y_pred == y_val)/len(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(StandardScaler(),DecisionTreeClassifier(random_state = 42) )\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "print('F1 SCORE: ',f1_score(y_val, y_pred, average = 'macro'))\n",
    "print('PRECISION:',precision_recall_fscore_support(y_val, y_pred, average='macro')[0])\n",
    "print('RECALL:',precision_recall_fscore_support(y_val, y_pred, average='macro')[1])\n",
    "print('ACCURACY:', sum(y_pred == y_val)/len(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OwUC3P8tc41w"
   },
   "outputs": [],
   "source": [
    "clf = make_pipeline(StandardScaler(), GradientBoostingClassifier(random_state = 42))\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "precision_recall = precision_recall_fscore_support(y_val, y_pred, average='macro')\n",
    "print('F1 SCORE: ',f1_score(y_val, y_pred, average = 'macro'))\n",
    "print('PRECISION:',precision_recall[0])\n",
    "print('RECALL:',precision_recall[1])\n",
    "print('ACCURACY:', sum(y_pred == y_val)/len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OwUC3P8tc41w"
   },
   "outputs": [],
   "source": [
    "clf = make_pipeline(MinMaxScaler(), GradientBoostingClassifier(random_state = 42))\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "precision_recall = precision_recall_fscore_support(y_val, y_pred, average='macro')\n",
    "print('F1 SCORE: ',f1_score(y_val, y_pred, average = 'macro'))\n",
    "print('PRECISION:',precision_recall[0])\n",
    "print('RECALL:',precision_recall[1])\n",
    "print('ACCURACY:', sum(y_pred == y_val)/len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SSoHJ33mdEgY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf = make_pipeline(StandardScaler(), GradientBoostingClassifier(random_state = 42))\n",
    "\n",
    "#def gridsearch\n",
    "params = {'gradientboostingclassifier__learning_rate' : [.2,.225,.25],#.285\n",
    "          'gradientboostingclassifier__n_estimators' : [70,75,80],\n",
    "          #'gradientboostingclassifier__n_iter_no_change':[2,5,10],\n",
    "          'gradientboostingclassifier__max_depth':[3,4,5]\n",
    "         }\n",
    "\n",
    "search = GridSearchCV(clf,param_grid=params,scoring='f1_macro',\n",
    "                                  n_jobs=-1,refit=True,verbose=1, pre_dispatch='10*n_jobs',\n",
    "                                  return_train_score=True)\n",
    "search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_params=search.best_params_\n",
    "gb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Xb7hb4jdUF8"
   },
   "outputs": [],
   "source": [
    "best_one=search.best_estimator_\n",
    "y_pred = best_one.predict(X_val)\n",
    "print(accuracy_score(y_val, y_pred), recall_score(y_val, y_pred, average='macro'), f1_score(y_val, y_pred, average = 'macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### One vs Rest Classifier (GB) - ORCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=make_pipeline(StandardScaler(), GradientBoostingClassifier(learning_rate=gb_params['gradientboostingclassifier__learning_rate'],n_estimators=gb_params['gradientboostingclassifier__n_estimators'],max_depth=gb_params['gradientboostingclassifier__max_depth'],random_state=42))\n",
    "classifier=ORC(clf)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_val)\n",
    "print(accuracy_score(y_val, y_pred), recall_score(y_val, y_pred, average='macro'), f1_score(y_val, y_pred, average = 'macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### One vs One Classifier (GB) - ORCO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=make_pipeline(StandardScaler(), GradientBoostingClassifier(learning_rate=gb_params['gradientboostingclassifier__learning_rate'],n_estimators=gb_params['gradientboostingclassifier__n_estimators'],max_depth=gb_params['gradientboostingclassifier__max_depth'],random_state=42))\n",
    "classifier=OOC(clf)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_val)\n",
    "print(accuracy_score(y_val, y_pred), recall_score(y_val, y_pred, average='macro'), f1_score(y_val, y_pred, average = 'macro'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Progetto_R.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
