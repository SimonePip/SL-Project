{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_veeJ32BrfR"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zxRpUUr-BnaJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9Lk7tXbB_Vf"
   },
   "source": [
    "# Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4TPaksx6CCw2"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset_completo.csv', header ='infer').iloc[:,1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1SjeiTzLDz3J"
   },
   "source": [
    "# Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nk6Vu9B8FKUC"
   },
   "source": [
    "### Train Test Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zPpV61yRFRd2"
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Vh8Mxd3IFn3-"
   },
   "outputs": [],
   "source": [
    "Y = data['class'] # Extract the target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TjwRGC1LF_yM"
   },
   "outputs": [],
   "source": [
    "X = data.drop(columns = ['class','score','publ','titolo']) # Remove from the data useful to the analysis: \"score, publ, titolo, class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4kcZ6zbkM71k"
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(X['genere'])\n",
    "X['genere'] = le.transform(X['genere']) # Transform the Categorical genere feature in a numerical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5xfQwZB6GN5C"
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,Y, train_size=.8, random_state=42) # Split dataset in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "NnylF4nyHP05"
   },
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val = train_test_split(X_train,y_train, train_size = .8, random_state = 42) # Split train in train and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "McL-rf4EIETM"
   },
   "source": [
    "### Excursus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfJ_pNuoIggO"
   },
   "source": [
    "We want to predict the class of a given video. The classes were defined using a home-made score.\n",
    "\n",
    "To predict we will try different models.\n",
    "Let's start with SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sihcOc9uI77Y"
   },
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Nf67Y6igJRo7"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxSP1WkcJzIn"
   },
   "source": [
    "REMINDER OF THE PARAMETERS\n",
    "\n",
    "\n",
    "C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=- 1, decision_function_shape='ovr', break_ties=False, random_state=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOwe20T2JYWN"
   },
   "source": [
    "Try to use SVC without scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sT1V1xqOMskK",
    "outputId": "d81d3c1e-2765-47f5-ea02-3ba82ae68a3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score using SVC without scaling data:  0.16061185468451242\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(gamma = 'auto', random_state = 42)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "print('f1-score using SVC without scaling data: ',f1_score(y_val, y_pred, average = 'macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vbBrjFoJUAIv"
   },
   "source": [
    "Try to use SVC with Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GOLK38YuUIO0",
    "outputId": "5e42c141-5d75-487d-cf12-62154784483d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score using SVC without scaling data:  0.8075326343334872\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto',random_state = 42))\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "print('f1-score using SVC without scaling data: ',f1_score(y_val, y_pred, average = 'macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKoLo8RcUuK8"
   },
   "source": [
    "Try to use SVC with MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6R5IQpLSU1f0",
    "outputId": "618acf6f-65ca-457b-a5fe-f0450fc43bbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score using SVC without scaling data:  0.5932135459307548\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(MinMaxScaler(), SVC(gamma='auto',random_state = 42))\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "print('f1-score using SVC without : ',f1_score(y_val, y_pred, average = 'macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r4nb9eD-VBc_"
   },
   "source": [
    "Try to use SVC with MinMaxScaler and Standard Scaler (in that order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h-zC-ZjtVKW0",
    "outputId": "fb50c2aa-3bc6-4266-b11c-d5bc2b1c4250"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score using SVC without scaling data:  0.8075326343334872\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(MinMaxScaler(),StandardScaler(), SVC(gamma='auto',random_state = 42))\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "print('f1-score using SVC without scaling data: ',f1_score(y_val, y_pred, average = 'macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSCZ8ep5VZmm"
   },
   "source": [
    "Try to use SVC with Standard Scaler and MinMaxScaler (in that order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GXpKohSrVhH_",
    "outputId": "b1cc0eb0-10ed-4ebd-e7be-08217907a407"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score using SVC without scaling data:  0.5932135459307548\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(StandardScaler(),MinMaxScaler(), SVC(gamma='auto',random_state = 42))\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "print('f1-score using SVC without scaling data: ',f1_score(y_val, y_pred, average = 'macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JzDW9SRVpeJ"
   },
   "source": [
    "Same Results as One Scaler.\n",
    "\n",
    "\n",
    "Best Results without S."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EI9EA1GqV2Sc"
   },
   "source": [
    "\n",
    "## DA FARE:    SVC GRIDSEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "5L6gQzt-XzJL"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QUL7jdepWgXj",
    "outputId": "d60b9354-c42f-4c6f-85bb-d39b56d2f83f"
   },
   "outputs": [],
   "source": [
    "\n",
    "svc = SVC()\n",
    "\n",
    "#def gridsearch\n",
    "params = {\n",
    "    #'kernel' : ('poly', 'rbf', 'sigmoid'),\n",
    "    'C' : np.linspace(0, 100, num=5), \n",
    "    'epsilon' : np.linspace(.001, 10, num=5), \n",
    "    #'degree' : [3,5,8],\n",
    "    #'gamma' : ('auto','scale')\n",
    "    \n",
    "}\n",
    "\n",
    "search = GridSearchCV(svc,param_grid=params,scoring='f1_macro',\n",
    "                                  n_jobs=-1,refit=True,verbose=10, pre_dispatch='10*n_jobs',\n",
    "                                  return_train_score=True)\n",
    "search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score using Random Forest without scaling data:  0.9425383988190441\n"
     ]
    }
   ],
   "source": [
    "clf = RFC(random_state = 42)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "print('f1-score using Random Forest without scaling data: ',f1_score(y_val, y_pred, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score using Random Forest with MinMaxScalre :  0.9462186951230818\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(MinMaxScaler(), RFC(random_state = 42))\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "print('f1-score using Random Forest with MinMaxScalre : ',f1_score(y_val, y_pred, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score using Random Forest with StandardScaler :  0.9425383988190441\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(StandardScaler(), RFC(random_state = 42))\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "print('f1-score using Random Forest with StandardScaler : ',f1_score(y_val, y_pred, average = 'macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)[source]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('minmaxscaler', MinMaxScaler()),\n",
       "                                       ('randomforestclassifier',\n",
       "                                        RandomForestClassifier(n_jobs=-1,\n",
       "                                                               random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'randomforestclassifier__criterion': ['gini',\n",
       "                                                               'entropy'],\n",
       "                         'randomforestclassifier__max_features': [None],\n",
       "                         'randomforestclassifier__n_estimators': [50, 100,\n",
       "                                                                  200]},\n",
       "             pre_dispatch='10*n_jobs', return_train_score=True,\n",
       "             scoring='f1_macro', verbose=10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = make_pipeline(MinMaxScaler(), RFC(random_state = 42, n_jobs = -1))\n",
    "\n",
    "#def gridsearch\n",
    "params = {'randomforestclassifier__criterion' : ['gini','entropy'],\n",
    "          'randomforestclassifier__max_features' : [None],\n",
    "          'randomforestclassifier__n_estimators' : [50,100,200]\n",
    "          \n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "search = GridSearchCV(clf,param_grid=params,scoring='f1_macro',\n",
    "                                  n_jobs=-1,refit=True,verbose=10, pre_dispatch='10*n_jobs',\n",
    "                                  return_train_score=True)\n",
    "search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_one=search.best_estimator_\n",
    "y_pred = best_one.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9497116153062941"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_val, y_pred, average = 'macro')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Progetto_R.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
